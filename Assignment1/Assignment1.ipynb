{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style='text-aling:center;color:Navy'>  Big Data Systems - Laboratory 1  </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topics included in this lab: \n",
    "- 1) Map-Reduce (20 minutes) \n",
    "- 2) Semistructured DS: Spanner DB (20 minutes) \n",
    "- 3) Bigtable (20 minutes)\n",
    "\n",
    "We have allocated 15 minutes for set up and/or to address any other issues.\n",
    "\n",
    "This is the first Lab for the Big Data Systems course - Fall 2021.\n",
    "We are covering the following topics:\n",
    "\n",
    "- Map-Reduce\n",
    "- Spanner\n",
    "- Bigtable\n",
    "\n",
    "The lab will have an in-class section as well as a homework section.\n",
    "You need to submit your in-class notebook before the end of the class. For the homework section, please refer to Canvas for the due date."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#In order to do this lab, you will need to open a terminal inside the browser.\n",
    "\n",
    "#Click on new -> terminal\n",
    "\n",
    "#You will see the terminal. Looks like this.\n",
    "\n",
    "ssh ucdenver@node5\n",
    "password: ucdenver\n",
    "#Make a directory in hadoop environment\n",
    "```\n",
    "sudo -u hdoop /home/hdoop/hadoop-2.10.1/bin/hadoop dfs  -mkdir /user/<firstname_lastname>\n",
    "```\n",
    "You can see your directory here http://node5.ucdenver.pvt:50070/explorer.html#/user/<firstname_lastname>\n",
    "```\n",
    "e.g: sudo -u hdoop /home/hdoop/hadoop-2.10.1/bin/hadoop dfs  -mkdir /user/khang_nguyen\n",
    "```\n",
    "#Make a subdirectory inside <firstname_lastname> in hadoop environment\n",
    "```\n",
    "sudo -u hdoop /home/hdoop/hadoop-2.10.1/bin/hadoop dfs  -mkdir /user/firstname_lastname/input\n",
    "e.g: sudo -u hdoop /home/hdoop/hadoop-2.10.1/bin/hadoop dfs  -mkdir /user/khang_nguyen/input\n",
    "```\n",
    "#Make a directory with your name\n",
    "```\n",
    "mkdir firstname_lastname\n",
    "e.g: mkdir khang_nguyen\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Count Example\n",
    "<hr>\n",
    "## Map/Reduce Classes\n",
    "We have three classes available:<br>\n",
    "<li>WordCount.Java              *#Main program*\n",
    "<li>WordcountMapper.java        *#Implementation of the Map*\n",
    "<li>WordCountReducer.java       *#Implementation of the Reduce*\n",
    "<br>\n",
    "Take a look at the Main program, try to identify where the files are loaded.\n",
    "<br>\n",
    "In the same fashion, inspect the Mapper and the Reduccer class to identify the emit and the collect steps on the code. \n",
    "<br> \n",
    "Now, let's run the WordCount:\n",
    "    \n",
    "### Transfer files folder to ucdenver@node5/<firstname_lastname>\n",
    "```\n",
    "winscp transfer file folder to firstname_lastname\n",
    "```\n",
    "    \n",
    "e.g:\n",
    "```    \n",
    "```\n",
    "### Compiling:\n",
    "``` \n",
    "export HADOOP_CLASSPATH=$(/home/hdoop/hadoop-2.10.1/bin/hadoop classpath)\n",
    "javac -classpath ${HADOOP_CLASSPATH}  *.java\n",
    "```\n",
    "### Making the JAR\n",
    "```\n",
    "jar cf WordCount.jar WordCount*.class\n",
    "```\n",
    "### Running hadoop Program\n",
    "```\n",
    "sudo -u hdoop /home/hdoop/hadoop-2.10.1/bin/hadoop jar WordCount.jar WordCount /user/firstname_lastname/input /user/firstname_lastname/output/1\n",
    "```    \n",
    "###Verify the output here \n",
    "```\n",
    "http://node5.ucdenver.pvt:50070/explorer.html#/user/<firstname_lastname>\n",
    "```\n",
    "## Paste your output in the next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### OUTPUT Goes HERE #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Using the _**hdfs dfs -get**_ bring the files in the output directory of the HDFS.\n",
    "- Using the _**head**_ command extract the first 10 rows of one of the output files. \n",
    "\n",
    "## Paste your output in the next cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### OUTPUT Goes HERE #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Inspect the output by using the commands cat, grep, tail, head.\n",
    "- Did you notice any issues on how the counting was done? For example, look a the word \"them\". Was the output as you expected to be?\n",
    "- If not, how can you address the problem. \n",
    "\n",
    "## Write your answer in the next cell. You don't need to implement the actual response. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### OUTPUT Goes HERE #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:RED\">Homework: </span> Department monthly sales\n",
    "<hr>\n",
    "Based on the map-reduce example above, do the proper modifications to solve the following problem:\n",
    "<br>\n",
    "We are going to be using the Walmart Store Sales Forecasting competition training dataset available [here](https://www.kaggle.com/c/walmart-recruiting-store-sales-forecasting/data). Considering this dataset, you should produce a monthly summary of the sales per department. <br>\n",
    "So you output should be like:\n",
    "<pre>\n",
    "dept-year-month:$$$\n",
    "</pre>\n",
    "1. Download the training dataset and upload it to your server for processing. Be careful with the paths you use.\n",
    "2. Using the three provided java classes as a template, create three new classes: __*Walmart.java, WalmartMapper.java, WalmartReducer.java*__ with the proper code.\n",
    "3. Fill in the following and submit all your files on Canvas to the Assignment 1.\n",
    "\n",
    "Complete the following:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Place your map function in the next cell:  <span style=\"font-size:12px\">(Only the function) </span>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### OUTPUT Goes HERE #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Place your reduce function in the next cell:  <span style=\"font-size:12px\">(Only the function) </span>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### OUTPUT Goes HERE #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Place your running output in the next cell:  <span style=\"font-size:12px\"> </span>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### OUTPUT Goes HERE #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Place the first 10 rows of your exit in the next cell:  <span style=\"font-size:12px\">(take a look at the _wc_ linux command) </span>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### OUTPUT Goes HERE #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:#3665af\">Section #2: Spanner </span><span style=\"font-size:15px\">(Estimated time: 20 minutes) </span>\n",
    "\n",
    "<hr>\n",
    "In this section we will practice how to use Google's Spanner database. \n",
    "## Pre-reqs:\n",
    "Your Google cloud account should be ready to deploy services.<br>\n",
    "\n",
    "### Create a Spanner Instance.\n",
    "\n",
    "- Create a spanner instace, and annotate the Instance ID. \n",
    "- We will use lab1-section2 as instance id in this lab; if you are using another id, you need to change in the connection settings. \n",
    "- For this test, configuring one node will suffice. \n",
    "\n",
    "### Installing the Python Client. \n",
    "We need to have the google-cloud library installed in our system.<br>\n",
    "If you are using windows/mac, go to the anaconda navigator, then Environments. Click the arrow next to _base (root)_ and select Open terminal. <br>\n",
    "Then execute the following pip command to install the client library. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` bash\n",
    "$> pip install google-cloud\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the Service Account File\n",
    "As mentioned in the cloud setup instructions, you need to generate a token file so you will be able to connect to spanner. Refer to that document for help. <br>\n",
    "Here is the summary of the steps. \n",
    "1. Go to APIS & Services\n",
    "2. Go to Credentials\n",
    "3. Select Create Credentials, and choose Service account key.\n",
    "4. Select Compute Engine default service account and Key type JSON. Then Create. \n",
    "5. Pick the file that was automatically downloaded, and store it in your BSD directory. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hands on..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports the Google Cloud Client Library.\n",
    "from google.cloud import spanner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JSON_SERVICE_KEY = 'path/filename to the google cloud key'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can learn more about creating instances and using Spanner with Python at [Google Documentation](https://cloud.google.com/spanner/docs/getting-started/python/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explicit():\n",
    "    ## Function to connect to spanner\n",
    "    from google.cloud import storage\n",
    "\n",
    "    # Explicitly use service account credentials by specifying the private key\n",
    "    # file.\n",
    "    storage_client = storage.Client.from_service_account_json(JSON_SERVICE_KEY)\n",
    "\n",
    "    # Make an authenticated API request\n",
    "    buckets = list(storage_client.list_buckets())\n",
    "    print(buckets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can get help about authentication at [Google Documentation](https://cloud.google.com/docs/authentication/production#auth-cloud-explicit-python)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warm up\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Instantiate a client.\n",
    "spanner_client = spanner.Client()\n",
    "\n",
    "# Your Cloud Spanner instance ID.\n",
    "instance_id = 'lab1-section2'\n",
    "\n",
    "# Get a Cloud Spanner instance by ID.\n",
    "instance = spanner_client.instance(instance_id)\n",
    "\n",
    "# Your Cloud Spanner database ID.\n",
    "database_id = 'lab1-db'           # If you did not create the database already, createit using the cloud console\n",
    "\n",
    "# Get a Cloud Spanner database by ID.\n",
    "database = instance.database(database_id)\n",
    "\n",
    "# Execute a simple SQL statement.\n",
    "with database.snapshot() as snapshot:\n",
    "    results = snapshot.execute_sql('SELECT current_date')\n",
    "\n",
    "    for row in results:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you didn't recevie an error and the current date was displayed, it means that at this point we're connected to our Spanner database.<rb>\n",
    "\n",
    "### Let's create a couple of tables\n",
    "This may take a minute. If you use your google cloud dashboard, you can see the two new tables as you refresh the page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operation =database.update_ddl(ddl_statements=[\n",
    "    \"\"\"CREATE TABLE Singers (\n",
    "        SingerId     INT64 NOT NULL,\n",
    "        FirstName    STRING(1024),\n",
    "        LastName     STRING(1024),\n",
    "        SingerInfo   BYTES(MAX)\n",
    "    ) PRIMARY KEY (SingerId)\"\"\"\n",
    "    ,\n",
    "    \"\"\"CREATE TABLE Albums (\n",
    "        SingerId     INT64 NOT NULL,\n",
    "        AlbumId      INT64 NOT NULL,\n",
    "        AlbumTitle   STRING(MAX)\n",
    "    ) PRIMARY KEY (SingerId, AlbumId),\n",
    "      INTERLEAVE IN PARENT Singers ON DELETE CASCADE\"\"\"\n",
    "])\n",
    "\n",
    "# operation = database.create()\n",
    "\n",
    "print('Waiting for operation to complete...')\n",
    "operation.result()\n",
    "\n",
    "print('Created tables in database {} on instance {}'.format( database_id, instance_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION:\n",
    "**_In which line the command that creates the database is actually executed on Spanner?_** Explain briefly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:red\"> --- Answer HERE --- </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's insert some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"Inserts sample data into the given database.\n",
    "   The database and table must already exist.\n",
    "\"\"\"\n",
    "\n",
    "with database.batch() as batch:\n",
    "    batch.insert(\n",
    "        table='Singers',\n",
    "        columns=('SingerId', 'FirstName', 'LastName',),\n",
    "        values=[\n",
    "            (1, u'Marc', u'Richards'),\n",
    "            (2, u'Catalina', u'Smith'),\n",
    "            (3, u'Alice', u'Trentor'),\n",
    "            (4, u'Lea', u'Martin'),\n",
    "            (5, u'David', u'Lomond')])\n",
    "    batch.commit\n",
    "    \n",
    "    batch.insert(\n",
    "        table='Albums',\n",
    "        columns=('SingerId', 'AlbumId', 'AlbumTitle',),\n",
    "        values=[\n",
    "            (1, 1, u'Total Junk'),\n",
    "            (1, 2, u'Go, Go, Go'),\n",
    "            (2, 1, u'Green'),\n",
    "            (2, 2, u'Forever Hold Your Peace'),\n",
    "            (2, 3, u'Terrified')])\n",
    "    batch.commit\n",
    "print('Inserted data.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION:\n",
    "**_How many statements were executed in Spanner?_** Explain briefly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:red\"> --- Answer HERE --- </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Querying the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Queries sample data from the database using SQL.\"\"\"\n",
    "\n",
    "\n",
    "with database.snapshot() as snapshot:\n",
    "    results = snapshot.execute_sql(\n",
    "        'SELECT SingerId, AlbumId, AlbumTitle FROM Albums')\n",
    "    \n",
    "    display(results)\n",
    "    \n",
    "    for row in results:\n",
    "        display(row)\n",
    "        print('SingerId: {}, AlbumId: {}, AlbumTitle: {}'.format(*row))\n",
    "        #print(\"SingerId: \",row[0],\", AlbumId: \",row[1],\", AlbumTitle: \",row[2], )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTIONS:\n",
    "1. **What kind of object is _results_?**\n",
    "2. **What kind of object is _row_?**\n",
    "3. **How is row being accessed?** _**Tip**_: take a look at the commented line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:red\"> --- Answer HERE --- </span>\n",
    "1. answer\n",
    "2. answer\n",
    "3. answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Reads sample data from the database.\"\"\"\n",
    "\n",
    "with database.snapshot() as snapshot:\n",
    "    keyset = spanner.KeySet(all_=True)\n",
    "    results = snapshot.read(\n",
    "        table='Albums',\n",
    "        columns=('SingerId', 'AlbumId', 'AlbumTitle',),\n",
    "        keyset=keyset,)\n",
    "\n",
    "    for row in results:\n",
    "        print('SingerId: {}, AlbumId: {}, AlbumTitle: {}'.format(*row))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTIONS:\n",
    "**_What is the difference between the first and second part of the code?_**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:red\"> --- Answer HERE --- </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's load some interesting data\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Instantiate a client.\n",
    "spanner_client = spanner.Client()\n",
    "\n",
    "# Your Cloud Spanner instance ID.\n",
    "instance_id = 'lab1-section2'\n",
    "\n",
    "# Get a Cloud Spanner instance by ID.\n",
    "instance = spanner_client.instance(instance_id)\n",
    "\n",
    "# Your Cloud Spanner database ID.\n",
    "database_id = 'lab1-db2'                             ## Create new Database\n",
    "\n",
    "# Get a Cloud Spanner database by ID.\n",
    "database = instance.database(database_id)\n",
    "\n",
    "# Execute a simple SQL statement.\n",
    "with database.snapshot() as snapshot:\n",
    "    results = snapshot.execute_sql('SELECT current_date')\n",
    "\n",
    "    for row in results:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time=time()\n",
    "operation =database.update_ddl(ddl_statements=[\n",
    "    \"\"\"CREATE TABLE RadiationMeasurements\n",
    "        (\n",
    "           CapturedTime timestamp,\n",
    "           Latitude float64,\n",
    "           Longitude float64,\n",
    "           Value float64,\n",
    "           Unit String(2048),\n",
    "           Location String(2048),\n",
    "           DeviceID String(2048),\n",
    "           MD5Sum String(2048),\n",
    "           Height String(2048),\n",
    "           Surface String(2048),\n",
    "           Radiation String(2048),\n",
    "           UploadedTime timestamp,\n",
    "           LoaderID float64\n",
    "        )PRIMARY KEY (CapturedTime,Latitude,Longitude,Location,UploadedTime,MD5Sum)\"\"\"\n",
    "])\n",
    "\n",
    "# operation = database.create()\n",
    "\n",
    "print('Waiting for operation to complete...')\n",
    "operation.result()\n",
    "\n",
    "print('Created tables in database {} on instance {}'.format(\n",
    "    database_id, instance_id))\n",
    "\n",
    "end_time=time()\n",
    "\n",
    "print (\"run time:\",end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Measures        = pd.read_csv(\"/path/to/measurements.sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Measures.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myData=[]\n",
    "for index,row in df_Measures[0:5].iterrows():\n",
    "    aDateTime = datetime.datetime.strptime(row[\"Captured Time\"], '%Y-%m-%d %H:%M:%S')\n",
    "    display('Row: {}, Timestamp: {} Lat/Lon:{}/{}'.format(index,aDateTime,row[\"Latitude\"],row[\"Longitude\"]))\n",
    "    myData.append( (index,aDateTime)  )\n",
    "myData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     ****************************************************************\n",
    "#     TO-DO: Write here a while/for to insert the Primary key data for the first 10 rows. \n",
    "#     ****************************************************************\n",
    "\n",
    "# --Hints:\n",
    "#     Adapt the code from the sample. \n",
    "#     Generate an array inserting tuples (you should use an array and the function append )\n",
    "\n",
    "\n",
    "### Write your code here.\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:#5DB664\">DELETE YOUR SPANNER INSTANCE AS WHEN YOU FINNISHED </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:RED\">Homework: </span> Yelp Dataset\n",
    "<hr>\n",
    "Similar to the example above, we are going to be using the Yelp competition dataset available [here](https://www.kaggle.com/yelp-dataset/yelp-dataset/data). <br>\n",
    "You should:\n",
    "1. Download the dataset to your machine.\n",
    "2. Create a new database.\n",
    "3. Create the tables necessary, with the proper interleaving configuration to store the business and reviews.\n",
    "4. Load the yelp_business dataset.\n",
    "5. Load 10% of the yelp_review dataset.\n",
    "\n",
    "Hints:\n",
    "- You probably want to do several batchs. You can do that by using the **[start:end]** operator for the dataframes. \n",
    "- You may need to review the documentation for the [Spanner SQL](https://cloud.google.com/spanner/docs/query-syntax)\n",
    "\n",
    "## Questions:\n",
    "1. Report the time for loading each dataset.\n",
    "2. Compare the time to load the rows for the business and the reviews datasets.\n",
    "3. List the top 10 better/most rated businesses in Colorado. To simplify this, let's assume that the best rated business is the one with the higher sum of ratings. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PLACE YOUR CODE STARTING THIS POINT. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:#3665af\">Section #3: Bigtable </span><span style=\"font-size:15px\">(Estimated time: 20 minutes) </span>\n",
    "\n",
    "<hr>\n",
    "In this section we will practice how to use Google's Bigtable database. \n",
    "## Pre-reqs:\n",
    "Your Google cloud account should be ready to deploy services.<br>\n",
    "\n",
    "### Create a Bigtable Instance\n",
    "\n",
    "- Create a development Bigtable instace, and annotate the Instance ID. \n",
    "- We will use lab1-section3 instance id in this lab; if you are using another id, you need to change in the connection settings. \n",
    "- For this test, use a development instance, which has only one node but is way cheaper. \n",
    "\n",
    "\n",
    "### Installing the Python Client\n",
    "We need to have the google cloud library installed in our system.<br>\n",
    "If you are using windows/mac, go to the Anaconda navigator, then Environments. Click the arrow next to _base (root)_ and select Open terminal. <br>\n",
    "Then execute the following pip command to install the client library. \n",
    "\n",
    "<pre>\n",
    "$> pip install google-cloud \n",
    "$> pip install google-cloud-happybase\n",
    "</pre>\n",
    "\n",
    "### Getting the Service Account File\n",
    "As mentioned in the cloud set up instructions, you need to generate a token file so you will be able to connect to bigtable. Refer to that document for help, especially if you did not manage to implement lab 1 section #2\n",
    "\n",
    "Documentation [here](http://google-cloud-python.readthedocs.io/en/latest/bigtable/usage.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hands on..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JSON_SERVICE_KEY = 'JSON SERVICE KEY PATH AND FILENAME'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can learn more about creating instances and using Spanner with Python at [Google Documentation](https://cloud.google.com/spanner/docs/getting-started/python/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explicit():\n",
    "    ## Function to connect to spanner\n",
    "    from google.cloud import storage\n",
    "\n",
    "    # Explicitly use service account credentials by specifying the private key\n",
    "    # file.\n",
    "    storage_client = storage.Client.from_service_account_json(JSON_SERVICE_KEY)\n",
    "\n",
    "    # Make an authenticated API request\n",
    "    buckets = list(storage_client.list_buckets())\n",
    "    print(buckets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can get help about authentication at [Google Documentation](https://cloud.google.com/docs/authentication/production#auth-cloud-explicit-python)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warm up\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_id  = \"bigdatasystems-fall2021\"\n",
    "instance_id = \"lab1-section3\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#5DB664\">Using Bigtable Client</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports the Google Cloud Client Library.\n",
    "from google.cloud import bigtable\n",
    "\n",
    "# The client must be created with admin=True because it will create a table.\n",
    "client     = bigtable.Client(project=project_id, admin=True)\n",
    "instance   = client.instance(instance_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I you didn't receive an error, it means that at this point we're connected to our Bigtable database.<rb>\n",
    "\n",
    "### Let's create a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name  = \"greetings\"\n",
    "print('Creating the {} table.'.format(table_name))\n",
    "\n",
    "table = instance.table(table_name)\n",
    "table.create()\n",
    "\n",
    "column_family_name = 'cf1'\n",
    "cf1 = table.column_family(column_family_name)\n",
    "cf1.create()\n",
    "\n",
    "#table.delete()  #to delete the table.\n",
    "\n",
    "print(\"done!\")\n",
    "### WARNING\n",
    "#\n",
    "## You will get an error the first time saying that you did not enable admin api. \n",
    "## A link will be given. Follow it and enable the API And retry."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inserting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Writing some greetings to the table.')\n",
    "column_name = 'greeting'.encode('utf-8')\n",
    "greetings = [\n",
    "    'Hello World!',\n",
    "    'Hello Cloud Bigtable!',\n",
    "    'Hello Bigtable with Python!',\n",
    "]\n",
    "\n",
    "for i, value in enumerate(greetings):\n",
    "    row_key = 'greeting{}'.format(i)\n",
    "    row = table.row(row_key)\n",
    "    row.set_cell(   \n",
    "                    column_family_name,\n",
    "                    column_name,\n",
    "                    value.encode('utf-8')\n",
    "                )\n",
    "    row.commit()\n",
    "    \n",
    "\n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Getting a single greeting by row key.')\n",
    "key = 'greeting0'\n",
    "\n",
    "row = table.read_row(key.encode('utf-8'))\n",
    "\n",
    "value = row.cells[column_family_name][column_name][0].value\n",
    "\n",
    "print('\\t{}: {}'.format(key, value.decode('utf-8')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Scanning for all greetings:')\n",
    "partial_rows = table.read_rows()\n",
    "partial_rows.consume_all()\n",
    "\n",
    "for row_key, row in partial_rows.rows.items():\n",
    "    key = row_key.decode('utf-8')\n",
    "    cell = row.cells[column_family_name][column_name][0]\n",
    "    value = cell.value.decode('utf-8')\n",
    "    print('\\t{}: {}'.format(key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#5DB664\">Using Happybase Client</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports the Google Cloud Client Library.\n",
    "from google.cloud import happybase\n",
    "\n",
    "# The client must be created with admin=True because it will create a table.\n",
    "\n",
    "client     = bigtable.Client(project=project_id, admin=True)\n",
    "instance   = client.instance(instance_id)\n",
    "connection = happybase.Connection(instance=instance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I you didn't receive an error, it means that at this point we're connected to our Bigtable database.<rb>\n",
    "\n",
    "### Let's create a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name  = \"greetings2\"\n",
    "print('Creating the {} table.'.format(table_name))\n",
    "column_family_name = 'cf1'\n",
    "connection.create_table(    table_name,\n",
    "                            {\n",
    "                                column_family_name: dict()     # Use default options.\n",
    "                            }\n",
    "                       )\n",
    "### WARNING\n",
    "#\n",
    "## You will get an error the first time saying that you did not enable admin api. \n",
    "## A link will be given. Follow it and enable the API And retry."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inserting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('Writing some greetings to the table.')\n",
    "table = connection.table(table_name)\n",
    "column_name = '{fam}:greeting'.format(fam=column_family_name)\n",
    "greetings = [\n",
    "    'Hello World!',\n",
    "    'Hello Cloud Bigtable!',\n",
    "    'Hello HappyBase!',\n",
    "]\n",
    "\n",
    "for i, value in enumerate(greetings):\n",
    "    row_key = 'greeting{}'.format(i)\n",
    "    table.put(row_key, {column_name: value})\n",
    "\n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Getting a single greeting by row key.')\n",
    "key = 'greeting0'.encode('utf-8')\n",
    "row = table.row(key)\n",
    "print('\\t{}: {}'.format(key, row[column_name.encode('utf-8')]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Scanning for all greetings:')\n",
    "\n",
    "for key, row in table.scan():\n",
    "    print('\\t{}: {}'.format(key, row[column_name.encode('utf-8')]))\n",
    "\n",
    "#     print('Deleting the {} table.'.format(table_name))\n",
    "#     connection.delete_table(table_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's load some interesting data\n",
    "<hr>\n",
    "**We will use the bigtable client but it can be done using happybase too.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "from time import time\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Measures        = pd.read_csv(\"/path/to/measurements.sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name  = \"RadiationMeasurements\"\n",
    "table_columns = [\n",
    "                    (\"time\",\"Captured Time\"),(\"time\",\"Uploaded Time\"),\n",
    "                    (\"location\",\"Latitude\"),(\"location\",\"Longitude\"),(\"location\",\"Height\"),\n",
    "                    (\"measure\",\"Value\"),(\"measure\",\"Unit\"),\n",
    "                    (\"device\",\"Device ID\")\n",
    "                ]\n",
    "\n",
    "print('Creating the {} table.'.format(table_name))\n",
    "\n",
    "RadiationMeasurements = instance.table(table_name)\n",
    "RadiationMeasurements.create()\n",
    "\n",
    "\n",
    "columnFamilies = []\n",
    "for aColumn in table_columns:\n",
    "    columnFamilies.append(aColumn[0])\n",
    "columnFamilies = list(set(columnFamilies))\n",
    "\n",
    "for aColumnFamily in columnFamilies:\n",
    "    cf = table.column_family(aColumnFamily)\n",
    "    cf.create()\n",
    "     \n",
    "\n",
    "print(\"done!\")\n",
    "### WARNING\n",
    "#\n",
    "## You will get an error the first time saying that you did not enable admin api. \n",
    "## A link will be given. Follow it and enable the API And retry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RadiationMeasurements.delete()   #UNCOMMENT IF YOU NEED TO DROP THE TABLE. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index,dfRow in df_Measures.iterrows():\n",
    "    row_key = 'measurement_{}'.format(index)\n",
    "    row = RadiationMeasurements.row(row_key)\n",
    "    \n",
    "\n",
    "    for aColumn in table_columns:  #([0],[1]) maps to (columnFamily,columnName)\n",
    "        row.set_cell(   \n",
    "                        aColumn[0],\n",
    "                        aColumn[1],\n",
    "                        str(dfRow[aColumn[1]]).encode('utf-8')\n",
    "                    )\n",
    "    row.commit()\n",
    "\n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Scanning 5 Measurements:')\n",
    "partial_rows = RadiationMeasurements.read_rows(limit=5)\n",
    "partial_rows.consume_all()\n",
    "\n",
    "for row_key, row in partial_rows.rows.items():\n",
    "    key   = row_key.decode('utf-8')\n",
    "    rowArr = []\n",
    "    for aColumn in table_columns:\n",
    "        rowArr.append(row.cells[aColumn[0]][aColumn[1].encode(\"utf-8\")][0].value)\n",
    "    print(\"Key:\",key)\n",
    "    for i in range(len(table_columns)):\n",
    "        print(\"      Data:\",table_columns[i][0],table_columns[i][1],\":\",rowArr[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Scanning measurement 3 to 5:')\n",
    "partial_rows = RadiationMeasurements.read_rows(start_key=\"measurement_3\",end_key=\"measurement_5\")\n",
    "partial_rows.consume_all()\n",
    "\n",
    "for row_key, row in partial_rows.rows.items():\n",
    "    key   = row_key.decode('utf-8')\n",
    "    rowArr = []\n",
    "    for aColumn in table_columns:\n",
    "        rowArr.append(row.cells[aColumn[0]][aColumn[1].encode(\"utf-8\")][0].value)\n",
    "    print(\"Key:\",key)\n",
    "    for i in range(len(table_columns)):\n",
    "        print(\"      Data:\",table_columns[i][0],table_columns[i][1],\":\",rowArr[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION:\n",
    "**_In which line is the data actually fetched from Bigtable?_** Explain briefly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:red\"> --- Answer HERE --- </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Sum all Measurements that the unit is cpm:')\n",
    "\n",
    "###############\n",
    "####    TO DO HERE\n",
    "##############\n",
    "\n",
    "print (\"The sum is:\", totalSum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:#5DB664\">DELETE YOUR BIGTABLE INSTANCE AS WHEN YOU FINNISH </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr><BR>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:RED\">Homework: </span> Yelp Dataset\n",
    "<hr>\n",
    "Similar to the example above, we are going to be using the New York City - Buildings competition dataset available [here](https://www.kaggle.com/new-york-city/nyc-buildings/data). <br>\n",
    "You should:\n",
    "1. Download the dataset to your machine.\n",
    "2. Create a new database.\n",
    "3. Create the necessary tables to load the Brooklyn subset.\n",
    "4. Load the Brooklyn dataset, but be smart when uploading. If we don't have a value for a particular cell, don't load it into Bigtable.\n",
    "\n",
    "\n",
    "## Questions:\n",
    "1. Report the time for loading the dataset.\n",
    "2. Generate a report that for each zipcode displays the average of the lot and building front area. <br>\n",
    "In this query the performance is very important as you are reading a noticeable ammount of data. Came across with an initial procedure to solve the query. Later try to improve that code. Did your second implementation improved the running time? Explain why. Present the code used in both stages and the runtime for each one. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PLACE YOUR CODE STARTING THIS POINT. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
