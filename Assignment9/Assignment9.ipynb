{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style='text-aling:center;color:Navy'>  Big Data Systems - Assignment 9 </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:#3665af\">Big Spatial Data </span><span style=\"font-size:15px\">(Estimated time: 4 hours) </span>\n",
    "\n",
    "<hr>\n",
    "In this section, we will practice how to use a Hadoop-based system to analyze and visualize spatial data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size:30px;color:#3665af;background-color:#E9E9F5;padding:10px;\">Disclaimer </div>\n",
    "\n",
    "This assignment is based on GeoJinni, formerly known as Spatial Hadoop. This system extends Hadoop by adding new classes with new functionality. \n",
    "\n",
    "The assignment is structured as follows. The first section describe the installation process, which will be based on a Ubuntu 16.04 system. In section 2 we will learn basic commands of Spatial Hadoop. In section 3 we will use Pigeon, a pig extension for querying spatial data. and in the last section 4, we will use tools for visualizing the obtained results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size:30px;color:#3665af;background-color:#E9E9F5;padding:10px;\">Section 1 - Environment Set Up </div>\n",
    "\n",
    "As mentioned before, this assignment will run on Spatial Hadoop. This section presents a guideline to install all the necessary tools to run the assignment.\n",
    "\n",
    "This guide is based on Ubuntu 16 desktop. If you are using another system, you can either use this guide as guideline and research online how to install all the packages in your system, or use a virtual machine. We recommend the latter. \n",
    "\n",
    "The required packages are:\n",
    "- Java 8\n",
    "- Hadoop 2.7.6\n",
    "- Spatial Hadoop\n",
    "- Pig\n",
    "- Pigeon 0.2.1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size:20px;color:#F1F8FC;background-color:#0095EA;padding:10px;\">1. Install Java 8</div>\n",
    "Open a terminal, and run the following commands one by one. \n",
    "\n",
    "<pre style=\"background-color: #ebece4;padding: 10px;border-left: solid 4px darkred;\">\n",
    "sudo su -\n",
    "apt-get install openjdk-8*\n",
    "apt-get install maven maven*\n",
    "</pre>\n",
    "You can find a detailed guide here: \n",
    "https://askubuntu.com/questions/762999/how-to-install-java-8-in-ubuntu-16-04\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size:20px;color:#F1F8FC;background-color:#0095EA;padding:10px;\">2. Install Hadoop</div>\n",
    "In this assignment, we will use a single Hadoop node. In other words, we will not set up a cluster.\n",
    "For this kind of environmnet, the installation process is just downloaded and do minor configurations. \n",
    "\n",
    "We will assume the current user is _bigdata_.\n",
    "\n",
    "Open a web browser and download Hadoop 2.7.6. Note the version, as this is important.\n",
    "- A [direct download link](https://hadoop.apache.org/release/2.7.6.html).\n",
    "\n",
    "- A detailed [installation guide](http://hadoop.apache.org/docs/r2.7.2/hadoop-project-dist/hadoop-common/SingleCluster.html) is available.\n",
    "\n",
    "Once the file is downloaded, on the same terminal you used to install java (running commandas as root):\n",
    "\n",
    "<pre style=\"background-color: #ebece4;padding: 10px;border-left: solid 4px darkred;\">\n",
    "apt install ssh\n",
    "apt install rsync\n",
    "</pre>\n",
    "\n",
    "Once that is done, open a new terminal (with the user _bigdata_):\n",
    "<pre style=\"background-color: #ebece4;padding: 10px;border-left: solid 4px orange;\">\n",
    "cd ~\n",
    "mkdir Hadoop\n",
    "cd Hadoop  #this is going to be our woriking directory\n",
    "tar xvf ~/Downloads/hadoop-2.7.6.tar.gz\n",
    "</pre>\n",
    "You probably need to switch to JAVA 8.\n",
    "<pre style=\"background-color: #ebece4;padding: 10px;border-left: solid 4px orange;\">\n",
    "sudo update-alternatives --config java\n",
    "</pre>\n",
    "We need to add the JAVA_HOME variable for Hadoop. To do that we will edit the configuration file.\n",
    "<pre style=\"background-color: #ebece4;padding: 10px;border-left: solid 4px orange;\">\n",
    "cd ~/Hadoop/hadoop-2.7.6/etc/hadoop\n",
    "vi hadoop-env.sh  # you can use nano if you prefer. \n",
    "</pre>\n",
    "\n",
    "Add the following line:\n",
    "<pre style=\"background-color: #ebece4;padding: 10px;border-left: solid 4px darkgreen;\">\n",
    "export JAVA_HOME=/usr/lib/jvm/java-8-oracle/jre/\n",
    "or\n",
    "export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java\n",
    "\n",
    "You can find the java path by running this command\n",
    "sudo update-alternatives --config java\n",
    "</pre>\n",
    "\n",
    "We are using this as a Stand-Alone server. Let's test our installation:\n",
    "<pre style=\"background-color: #ebece4;padding: 10px;border-left: solid 4px orange;\">\n",
    "cd ~/Hadoop\n",
    "~/Hadoop/hadoop-2.7.6/bin/hadoop version \n",
    "</pre>\n",
    "\n",
    "The output should be like this:\n",
    "<pre style=\"background-color: #ebece4;padding: 10px;border-left: solid 4px black;\">\n",
    "Hadoop 2.7.6\n",
    "Subversion https://shv@git-wip-us.apache.org/repos/asf/hadoop.git -r 085099c66cf28be31604560c376fa282e69282b8\n",
    "Compiled by kshvachk on 2018-04-18T01:33Z\n",
    "Compiled with protoc 2.5.0\n",
    "From source with checksum 71e2695531cb3360ab74598755d036\n",
    "This command was run using /home/bigdata/Hadoop/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6.jar\n",
    "</pre>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size:20px;color:#F1F8FC;background-color:#0095EA;padding:10px;\">3. Install Spatial Hadoop</div>\n",
    "As Spatial Hadoop is packed as a library (.jar) we need to download the software and copy it to the Hadoop installation directory.\n",
    "\n",
    "Open a web browser and download Spatial Hadoop from [Spatial Hadoop Website](http://spatialhadoop.cs.umn.edu/)\n",
    "- A [direct download link](http://spatialhadoop.cs.umn.edu/downloads/spatialhadoop-2.4.2-bin.tar.gz).\n",
    "\n",
    "Once you download the software, using the same terminal you used to install Hadoop (with the user _bigdata_) do the following:\n",
    "<pre style=\"background-color: #ebece4;padding: 10px;border-left: solid 4px orange;\">\n",
    "cd ~/Hadoop/hadoop-2.7.6\n",
    "tar xvf ~/Downloads/spatialhadoop-2.4.2-bin.tar.gz\n",
    "</pre>\n",
    "\n",
    "To test the installation run the following commands:\n",
    "<pre style=\"background-color: #ebece4;padding: 10px;border-left: solid 4px orange;\">\n",
    "cd ~/Hadoop\n",
    "~/Hadoop/hadoop-2.7.6/bin/shadoop \n",
    "</pre>\n",
    "\n",
    "The output should look like this:\n",
    "<pre style=\"background-color: #ebece4;padding: 10px;border-left: solid 4px black;\">\n",
    "An example program must be given as the first argument.\n",
    "Valid program names are:\n",
    "  closestpair: Computes the closest pair of point of an input set of points\n",
    "  convexhull: Computes the convex hull of an input set of points\n",
    "  delaunay: Computes the Delaunay triangulation for a set of points\n",
    "  distcp: Copies a directory or file using a MapReduce job\n",
    "  dj: Computes the spatial join between two input files using the distributed join algorithm\n",
    "  farthestpair: Computes the farthest pair of point of an input set of points\n",
    "  generate: Generates a random file containing spatial data\n",
    "  gplot: Plots a file to an image\n",
    "  hadoopviz: Run Hadoopviz Server\n",
    "  hdfplot: Plots a heat map for a give NASA dataset\n",
    "  hdfx: Extracts data from a set of HDF files to text files\n",
    "  hplot: Plots a heat map to an image\n",
    "  index: Spatially index a file using a specific indexer\n",
    "  knn: Finds the k nearest neighbor in a file to a point\n",
    "  lakesplot: Plots lakes to SVG image\n",
    "  mbr: Finds the minimal bounding rectangle of an input file\n",
    "  mplot: Plot using ImageMagick\n",
    "  multihdfplot: Plots NASA datasets in the spatiotemporal range provided by user\n",
    "  oldindex: Spatially index a file using a specific indexer\n",
    "  rangequery: Finds all objects in the query range given by a rectangle\n",
    "  readfile: Retrieve some information about the index of a file\n",
    "  sample: Reads a random sample from the input file\n",
    "  shahedindexer: Creates a multilevel spatio-temporal indexer for NASA data\n",
    "  sjmr: Computes the spatial join between two input files using the SJMR algorithm\n",
    "  skyline: Computes the skyline of an input set of points\n",
    "  staggquery: Runs a spatio temporal aggregate query on HDF files\n",
    "  union: Computes the union of input shapes\n",
    "  uunion: Computes the union of input shapes using the UltimateUnion algorithm\n",
    "  vizserver: Starts a server that handles visualization requests\n",
    "</pre>\n",
    "\n",
    "Which is the Spatial Hadoop online help."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size:20px;color:#F1F8FC;background-color:#0095EA;padding:10px;\">4. Install Pig</div>\n",
    "\n",
    "Open a web browser and download the lastest version of PIG (0.17) of Pig from the [website](http://pig.apache.org/)\n",
    "- A [direct download link](http://mirrors.gigenet.com/apache/pig/pig-0.17.0/pig-0.17.0.tar.gz).\n",
    "- A detailed [documentation](http://pig.apache.org/docs/r0.17.0/start.html) is available.\n",
    "\n",
    "Once the file is downloaded, open a new terminal (with the user _bigdata_):\n",
    "<pre style=\"background-color: #ebece4;padding: 10px;border-left: solid 4px orange;\">\n",
    "cd ~/Hadoop\n",
    "tar xvf ~/Downloads/pig-0.17.0.tar.gz\n",
    "</pre>\n",
    "\n",
    "We need to add the PIG path to our enviroment path. To do that we will edit bash resource config file.\n",
    "<pre style=\"background-color: #ebece4;padding: 10px;border-left: solid 4px orange;\">\n",
    "vi ~/.bashrc\n",
    "</pre>\n",
    "\n",
    "At the end of the file add:\n",
    "<pre style=\"background-color: #ebece4;padding: 10px;border-left: solid 4px darkgreen;\">\n",
    "export PATH=/home/bigdata/Hadoop/pig-0.17.0/bin:$PATH\n",
    "</pre>\n",
    "\n",
    "Let's re-load and test the enviroment. \n",
    "<pre style=\"background-color: #ebece4;padding: 10px;border-left: solid 4px orange;\">\n",
    "cd ~/Hadoop\n",
    ". ~/.bashrc\n",
    "pig -help\n",
    "</pre>\n",
    "\n",
    "The output should look like this:\n",
    "<pre style=\"background-color: #ebece4;padding: 10px;border-left: solid 4px black;\">\n",
    "Apache Pig version 0.17.0 (r1797386) \n",
    "compiled Jun 02 2017, 15:41:58\n",
    "\n",
    "USAGE: Pig [options] [-] : Run interactively in grunt shell.\n",
    "       Pig [options] -e[xecute] cmd [cmd ...] : Run cmd(s).\n",
    "       Pig [options] [-f[ile]] file : Run cmds found in file.\n",
    "  options include:\n",
    "    -4, -log4jconf - Log4j configuration file, overrides log conf\n",
    "    -b, -brief - Brief logging (no timestamps)\n",
    "    -c, -check - Syntax check\n",
    "    -d, -debug - Debug level, INFO is default\n",
    "    -e, -execute - Commands to execute (within quotes)\n",
    "    -f, -file - Path to the script to execute\n",
    "    -g, -embedded - ScriptEngine classname or keyword for the ScriptEngine\n",
    "    -h, -help - Display this message. You can specify topic to get help for that topic.\n",
    "        properties is the only topic currently supported: -h properties.\n",
    "    -i, -version - Display version information\n",
    "    -l, -logfile - Path to client side log file; default is current working directory.\n",
    "    -m, -param_file - Path to the parameter file\n",
    "    -p, -param - Key value pair of the form param=val\n",
    "    -r, -dryrun - Produces script with substituted parameters. Script is not executed.\n",
    "    -t, -optimizer_off - Turn optimizations off. The following values are supported:\n",
    "            ConstantCalculator - Calculate constants at compile time\n",
    "            SplitFilter - Split filter conditions\n",
    "            PushUpFilter - Filter as early as possible\n",
    "            MergeFilter - Merge filter conditions\n",
    "            PushDownForeachFlatten - Join or explode as late as possible\n",
    "            LimitOptimizer - Limit as early as possible\n",
    "            ColumnMapKeyPrune - Remove unused data\n",
    "            AddForEach - Add ForEach to remove unneeded columns\n",
    "            MergeForEach - Merge adjacent ForEach\n",
    "            GroupByConstParallelSetter - Force parallel 1 for \"group all\" statement\n",
    "            PartitionFilterOptimizer - Pushdown partition filter conditions to loader implementing LoadMetaData\n",
    "            PredicatePushdownOptimizer - Pushdown filter predicates to loader implementing LoadPredicatePushDown\n",
    "            All - Disable all optimizations\n",
    "        All optimizations listed here are enabled by default. Optimization values are case insensitive.\n",
    "    -v, -verbose - Print all error messages to screen\n",
    "    -w, -warning - Turn warning logging on; also turns warning aggregation off\n",
    "    -x, -exectype - Set execution mode: local|mapreduce|tez, default is mapreduce.\n",
    "    -F, -stop_on_failure - Aborts execution on the first failed job; default is off\n",
    "    -M, -no_multiquery - Turn multiquery optimization off; default is on\n",
    "    -N, -no_fetch - Turn fetch optimization off; default is on\n",
    "    -P, -propertyFile - Path to property file\n",
    "    -printCmdDebug - Overrides anything else and prints the actual command used to run Pig, including\n",
    "                     any environment variables that are set by the pig command.\n",
    "2018-05-03 15:05:07,029 INFO  [main] pig.Main (Main.java:printScriptRunTime(694)) - Pig script completed in 396 milliseconds (396 ms)\n",
    "\n",
    "</pre>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size:20px;color:#F1F8FC;background-color:#0095EA;padding:10px;\">5. Install Pigeon</div>\n",
    "\n",
    "Open a web browser and download the lastest version of Pigeon (0.2.1) and the configuration. \n",
    "- A [direct download link for Pigeon jar file](http://spatialhadoop.cs.umn.edu/pigeon/pigeon-0.1.jar).\n",
    "- A [direct download link for the import file](http://spatialhadoop.cs.umn.edu/pigeon/pigeon_import.pig).\n",
    "\n",
    "Also, we will need some additional libraries, that we set available for you here:\n",
    "- [JTS Topology Suite version 1.8.0](https://repo.maven.apache.org/maven2/com/vividsolutions/jts/1.8/jts-1.8.jar)\n",
    "- [ESRI Geometry API version 2.1.0](https://github.com/Esri/geometry-api-java/releases/download/v1.1.1/esri-geometry-api-1.1.1.jar)\n",
    "\n",
    "Pigeon [website](http://spatialhadoop.cs.umn.edu/pigeon/).\n",
    "\n",
    "Once the file is downloaded, open a new terminal (with the user _bigdata_):\n",
    "<pre style=\"background-color: #ebece4;padding: 10px;border-left: solid 4px orange;\">\n",
    "cd ~/Hadoop\n",
    "mv ~/Downloads/pigeon-0.1.jar ~/Hadoop\n",
    "mv ~/Downloads/pigeon_import.pig ~/Hadoop\n",
    "mv ~/Downloads/jts-1.8.0.jar ~/Hadoop\n",
    "mv ~/Downloads/esri-geometry-api-1.1.1.jar ~/Hadoop\n",
    "</pre>\n",
    "\n",
    "That should be all to have Pigeon available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "<div style=\"font-size:30px;color:#3665af;background-color:#E9E9F5;padding:10px;\">Section 2 - Basic Spatial Hadoop commands. </div>\n",
    "\n",
    "We can access the basic Spatial Hadoop commands by running the following in a terminal:\n",
    "<pre style=\"background-color: #ebece4;padding: 10px;border-left: solid 4px orange;\">\n",
    "~/Hadoop/hadoop-2.7.6/bin/shadoop &lt;utility&gt;\n",
    "</pre>\n",
    "\n",
    "To get help, just run the command without any parameters.\n",
    "<pre style=\"background-color: #ebece4;padding: 10px;border-left: solid 4px orange;\">\n",
    "~/Hadoop/hadoop-2.7.6/bin/shadoop \n",
    "</pre>\n",
    "\n",
    "You can also get help for a particular command by typing the command without parameters, like:\n",
    "<pre style=\"background-color: #ebece4;padding: 10px;border-left: solid 4px orange;\">\n",
    "~/Hadoop/hadoop-2.7.6/bin/shadoop generate\n",
    "</pre>\n",
    "will display:\n",
    "<pre style=\"background-color: #ebece4;padding: 10px;border-left: solid 4px black;\">\n",
    "Set MBR of the generated file using rect:&lt;x1,y1,x2,y2&gt;\n",
    "Generates a file with random shapes\n",
    "Parameters (* marks required parameters):\n",
    "&lt;output file&gt; - Path to the file to generate. If omitted, file is generated to stdout.\n",
    "mbr:&lt;x1,y1,x2,y2&gt; - (*) The MBR of the generated data. Originated at (x,y) with dimensions (w,h)\n",
    "shape:&lt;point|(rectangle)&gt; - Type of shapes in generated file\n",
    "sindex:&lt;grid&gt; - Type of global index in generated file. The only supported index is 'grid'\n",
    "seed:&lt;s&gt; - Use a specific seed to generate the file\n",
    "rectsize:&lt;rs&gt; - Maximum edge size for generated rectangles\n",
    "-overwrite - Overwrite output file without notice\n",
    "Generic options supported are\n",
    "-conf &lt;configuration file&gt;     specify an application configuration file\n",
    "-D &lt;property=value&gt;            use value for given property\n",
    "-fs &lt;local|namenode:port&gt;      specify a namenode\n",
    "-jt &lt;local|resourcemanager:port&gt;    specify a ResourceManager\n",
    "-files &lt;comma separated list of files&gt;    specify comma separated files to be copied to the map reduce cluster\n",
    "-libjars &lt;comma separated list of jars&gt;    specify comma separated jar files to include in the classpath.\n",
    "-archives &lt;comma separated list of archives&gt;    specify comma separated archives to be unarchived on the compute machines.\n",
    "\n",
    "The general command line syntax is\n",
    "bin/hadoop command [genericOptions] [commandOptions]\n",
    "<pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size:20px;color:#F1F8FC;background-color:#0095EA;padding:10px;\">1. Generating Random Shapes</div>\n",
    "\n",
    "Let's start simple. Let's generate random rectangles within the bounding box defined by _[ (0,0), (10000,10000) ]_.\n",
    "To do this we use the **generate** Spatial Hadoop command.\n",
    "\n",
    "We will create 200mb file, named test1, filled with rectangles. In a terminal type the following command:\n",
    "\n",
    "<pre style=\"background-color: #ebece4;padding: 10px;border-left: solid 4px orange;\">\n",
    " ~/Hadoop/hadoop-2.7.6/bin/shadoop generate test1 mbr:0,0,10000,10000 size:200.mb shape:rect -overwrite\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Paste the last 25 lines of the command output here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect the output\n",
    "\n",
    "<pre style=\"background-color: #ebece4;padding: 10px;border-left: solid 4px orange;\">\n",
    "ls -al ~/Hadoop/hadoop-2.7.6/test1\n",
    "head -20 ~/Hadoop/hadoop-2.7.6/test1/part-00000_data_00001 | nl\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Paste the output of the previous 2 commands here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size:20px;color:#F1F8FC;background-color:#0095EA;padding:10px;\">2. Indexing the data</div>\n",
    "\n",
    "<pre style=\"background-color: #ebece4;padding: 10px;border-left: solid 4px orange;\">\n",
    "~/Hadoop/hadoop-2.7.6/bin/shadoop index test1 test1.idx.grid mbr:0,0,10000,10000 sindex:grid shape:rect\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Paste the last 35 lines of the command output here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size:20px;background-color:#A74A54;color:#F1E6E7;padding:10px;\">\n",
    "    Question 2.2.1:\n",
    "</div>\n",
    "\n",
    "**How long did the indexing take?**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Place your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect the output\n",
    "\n",
    "<pre style=\"background-color: #ebece4;padding: 10px;border-left: solid 4px orange;\">\n",
    "ls -al ~/Hadoop/test1.idx.grid\n",
    "head -20 ~/Hadoop/test1.idx.grid/part-00000 | nl\n",
    "</pre>\n",
    "\n",
    "Also we can inspect the index by using a _shadoop_ command:\n",
    "<pre style=\"background-color: #ebece4;padding: 10px;border-left: solid 4px orange;\">\n",
    "~/Hadoop/hadoop-2.7.6/bin/shadoop readfile test1.idx.grid\n",
    "</pre>\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Paste the output of the previous 3 commands here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size:20px;background-color:#A74A54;color:#F1E6E7;padding:10px;\">\n",
    "    Question 2.2.2:\n",
    "</div>\n",
    "\n",
    "**How do you interpret each line of the file?**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Place your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size:20px;background-color:#0B6713;color:#F1E6E7;padding:10px;\">\n",
    "    TO-DO 2.2.3:\n",
    "</div>\n",
    "\n",
    "a) **Create a quadtree index named test1.idx.quad.**  \n",
    "b) **Inspect one of your output files (like we did before). Place a sample of the output below.**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "a) Place your command line here."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "a) Place the first 20 lines of each inspect command. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size:20px;color:#F1F8FC;background-color:#0095EA;padding:10px;\">3. Query the data</div>\n",
    "\n",
    "<pre style=\"background-color: #ebece4;padding: 10px;border-left: solid 4px orange;\">\n",
    "~/Hadoop/hadoop-2.7.6/bin/shadoop knn test1.idx.grid knn_results point:1000,1000 k:1000 shape:rect\n",
    "head -20 ~/Hadoop/hadoop-2.7.6/knn_results |nl\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Paste the output of both commands here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size:20px;background-color:#A74A54;color:#F1E6E7;padding:10px;\">\n",
    "    Question 2.3.1:\n",
    "</div>\n",
    "\n",
    "a) **Explain the shadoop knn command we just issued.**\n",
    "\n",
    "b) **How do you interpret each line of the output file?**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Place your answer here.\n",
    "a)\n",
    "b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size:20px;background-color:#0B6713;color:#F1E6E7;padding:10px;\">\n",
    "    TO-DO 2.1.2:\n",
    "</div>\n",
    "\n",
    "a) **Write the command to run a range query to extract all rectangles within the range _[ (30,500),  (1040,3050)]_.**\n",
    "\n",
    "b) **Briefly explain the command you issued**\n",
    "\n",
    "c) **How do you interpret each line of the output file?**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Place your command and answers here.\n",
    "a)\n",
    "b)\n",
    "c)\n",
    "\n",
    "Also place the first 10 lines of your query results. \n",
    "Note: Be careful reading the command output to make sure it runs correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "<div style=\"font-size:30px;color:#3665af;background-color:#E9E9F5;padding:10px;\">Section 3 - Query the data using Pigeon. </div>\n",
    "\n",
    "We will use Pigeon, an extension of Pig, to do some more complex queries. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size:20px;color:#F1F8FC;background-color:#0095EA;padding:10px;\">1. Download the data</div>\n",
    "\n",
    "Download the following files to your _~/Hadoop_ directory:\n",
    "\n",
    "- [Trajectories dataset](https://drive.google.com/file/d/1miwmKJw9z8B-GQuuM7eUfIZxh_LoNzNv/view?usp=sharing): containing a single trajectory (i.e. sequence of spatial locations over time).\n",
    "- [ZipCodes](https://drive.google.com/open?id=0B1jY75xGiy7eLWhNUll0ZWFRT0U)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size:20px;color:#F1F8FC;background-color:#0095EA;padding:10px;\">2. Running a simple query.</div>\n",
    "\n",
    "<pre style=\"background-color: #ebece4;padding: 10px;border-left: solid 4px orange;\">\n",
    "cd ~/Hadoop\n",
    "ls -al\n",
    "</pre>\n",
    "\n",
    "Among your files you should have:\n",
    "- pigeon-0.1.jar, \n",
    "- esri-geometry-api-1.1.1.jar, \n",
    "- jts-1.8.0.jar, \n",
    "- pigeon_import.pig file, and \n",
    "- the downloaded files in this directory. \n",
    "\n",
    "\n",
    "Let's count how many points are in the trajectory:\n",
    "<pre style=\"background-color: #ebece4;padding: 10px;border-left: solid 4px orange;\">\n",
    "wc -l trajectory.tsv\n",
    "</pre>\n",
    "\n",
    "\n",
    "Let's edit a simple query file.\n",
    "<pre style=\"background-color: #ebece4;padding: 10px;border-left: solid 4px orange;\">\n",
    "vi trajectory.pigeon    #you can use nano or other editor of your preference. \n",
    "</pre>\n",
    "\n",
    "and add this content:\n",
    "<pre style=\"background-color: #ebece4;padding: 10px;border-left: solid 4px darkgreen;\">\n",
    "REGISTER pigeon-0.2.1.jar;\n",
    "REGISTER jts-1.8.0.jar;\n",
    "REGISTER esri-geometry-api-2.1.0.jar;\n",
    "IMPORT 'pigeon_import.pig';\n",
    "\n",
    "points = LOAD 'trajectory.tsv' AS (type, time: datetime, lat:double, lon:double);\n",
    "s_points = FOREACH points GENERATE ST_MakePoint(lat, lon) AS point, time;\n",
    "points_by_time = ORDER s_points BY time;\n",
    "points_grouped = GROUP points_by_time ALL;\n",
    "lines = FOREACH points_grouped GENERATE ST_AsText(ST_MakeLine(points_by_time));\n",
    "STORE lines INTO 'trajectory';\n",
    "</pre>\n",
    "\n",
    "save the file and then run it\n",
    "\n",
    "<pre style=\"background-color: #ebece4;padding: 10px;border-left: solid 4px orange;\">\n",
    "pig -x local trajectory.pigeon\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size:20px;background-color:#0B6713;color:#F1E6E7;padding:10px;\">\n",
    "    TO-DO 3.2.1:\n",
    "</div>\n",
    "\n",
    "**Inspect the output and answer** \n",
    "\n",
    "a) **How many lines were generated?**\n",
    "\n",
    "b) **How do you interpret the output?**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Place your inspection command and answers here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size:20px;color:#F1F8FC;background-color:#0095EA;padding:10px;\">3. Running a spatial query.</div>\n",
    "\n",
    "We will use the Zipcode dataset and Pigeon to run a spatial query to get all the zipcode geometries that are close to Denver, CO. \n",
    "\n",
    "First, we need to decompress the dataset\n",
    "<pre style=\"background-color: #ebece4;padding: 10px;border-left: solid 4px orange;\">\n",
    "cd ~/Hadoop\n",
    "mv ~/Downloads/ZCTA5.csv.bz2 ~/Hadoop\n",
    "bunzip2 ZCTA5.csv.bz2\n",
    "</pre>\n",
    "The uncompressed file should be around 1Gb.\n",
    "\n",
    "\n",
    "Let's count how many zipcodes we have in the dataset:\n",
    "<pre style=\"background-color: #ebece4;padding: 10px;border-left: solid 4px orange;\">\n",
    "wc -l ZCTA5.csv\n",
    "</pre>\n",
    "\n",
    "\n",
    "Let's edit a simple query file.\n",
    "<pre style=\"background-color: #ebece4;padding: 10px;border-left: solid 4px orange;\">\n",
    "vi Denver_zipcodes.pigeon    #you can use nano or other editor of your preference. \n",
    "</pre>\n",
    "\n",
    "and add this content:\n",
    "<pre style=\"background-color: #ebece4;padding: 10px;border-left: solid 4px darkgreen;\">\n",
    "REGISTER pigeon-0.2.1.jar;\n",
    "REGISTER jts-1.8.0.jar;\n",
    "REGISTER esri-geometry-api-2.1.0.jar;\n",
    "IMPORT 'pigeon_import.pig';\n",
    "\n",
    "-- Load the dataset. We will use only two fields. \n",
    "rows = LOAD 'ZCTA5.csv'  USING PigStorage('\\t') AS (geometry, zipcode, ignore0,ignore1, ignore2, ignore3, ignore4, ignore5, ignore6, ignore7 );\n",
    "\n",
    "-- Uncomment if you want to try with less rows.\n",
    "-- rows = LIMIT rows 10;\n",
    "\n",
    "-- Reformat the data to get the zipcode, the geometry as an object, and the geometry as pure text (we will use this later)\n",
    "data = FOREACH rows GENERATE zipcode ,ST_GeomFromText( REPLACE(geometry,'\"','')) as geometry, REPLACE(geometry,'\"','') as geometryWKT ;\n",
    "\n",
    "-- Filter based on Denver, CO location and a radius of 6 degrees.\n",
    "results = FILTER data BY ST_Intersects(ST_Buffer(ST_MakePoint(-104.9903, 39.7392),6), geometry);\n",
    "\n",
    "-- Generate the export results.\n",
    "exports = FOREACH results GENERATE zipcode, geometryWKT;\n",
    "\n",
    "-- Store the results\n",
    "STORE exports INTO 'Denver_zipcodes';\n",
    "</pre>\n",
    "\n",
    "save the file and then run it\n",
    "\n",
    "<pre style=\"background-color: #ebece4;padding: 10px;border-left: solid 4px orange;\">\n",
    "pig -x local Denver_zipcodes.pigeon\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size:20px;background-color:#0B6713;color:#F1E6E7;padding:10px;\">\n",
    "    TO-DO 3.3.1:\n",
    "</div>\n",
    "\n",
    "**Inspect the output and answer the following questions:** \n",
    "\n",
    "a) **How many lines were generated?**\n",
    "\n",
    "b) **How do you interpret the output?**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Place your inspection command and answers here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size:20px;background-color:#0B6713;color:#F1E6E7;padding:10px;\">\n",
    "    TO-DO 3.3.2:\n",
    "</div>\n",
    "\n",
    "**Generate a new file, and name it *Colorado_zipcodes.pigeon* based on the Denver_zipcodes.pigeon that generates the geometries for the zipcodes of the State of Colorado.**\n",
    "You may use information from the Lab 8 to get the geometry for the State of Colorado.\n",
    "\n",
    "a) **Place your Colorado_zipcodes.pigeon file contents in the next cell.** *Save the output in Colorado_zipcodes folder*\n",
    "\n",
    "b) **How many lines were generated?**\n",
    "\n",
    "c) **List the first 10 results.** You will need to cut each line down to the first 50 characters. To do that use the bash command _cut -b_. Use _man cut_ to learn about this command.\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Place your Colorado_zipcodes.pigeon file contents in this cell."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Answer b here."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Place the results for (c) here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "<div style=\"font-size:30px;color:#3665af;background-color:#E9E9F5;padding:10px;\">Section 4 - Visualizing. </div>\n",
    "<br>\n",
    "<div style=\"font-size:20px;color:#F1F8FC;background-color:#0095EA;padding:10px;\">1. Using Python</div>\n",
    "\n",
    "Using what you learned in Lab 8, do the following:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size:20px;background-color:#0B6713;color:#F1E6E7;padding:10px;\">\n",
    "    TO-DO 4.1.1:\n",
    "</div>\n",
    "\n",
    "**Create a Map of the Denver Zipcodes** \n",
    "\n",
    "Using the output of your Pigeon queries, generate this. You may want to look at the function _shapely.wkt.loads_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLACE AND RUN YOUR PYTHON CODE HERE.\n",
    "# WHEN SUBMITTING, ATTACH YOUR DATA FILES FOR THIS SECTION.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size:20px;color:#F1F8FC;background-color:#0095EA;padding:10px;\">2. Using Spatial Hadoop </div>\n",
    "\n",
    "Spatial Hadoop has a visualization tool for plotting images or starting a webserver.\n",
    "Today we will use the plotting functionality, you can later play with HadoopViz.\n",
    "\n",
    "To generate an image of the geometry run:\n",
    "<pre style=\"background-color: #ebece4;padding: 10px;border-left: solid 4px orange;\">\n",
    "~/Hadoop/hadoop-2.7.6/bin/shadoop gplot Denver_zipcodes level:10 denver_vis.png shape:osm\n",
    "</pre>\n",
    "\n",
    "Then open the denver_vis.png file with your prefered graphic editor. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size:20px;background-color:#0B6713;color:#F1E6E7;padding:10px;\">\n",
    "    TO-DO 4.2.1:\n",
    "</div>\n",
    "\n",
    "Generate a image output from your Colorado Zipcodes query.  Attach the generated image and paste the command line to generate it. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Paste your command line here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<div style=\"font-size:20px;color:#F1F8FC;background-color:#0095EA;padding:10px;\">Useful commands </div>\n",
    "\n",
    "To compress the files use this command:\n",
    "\n",
    "<pre style=\"background-color: #ebece4;padding: 10px;border-left: solid 4px orange;\">\n",
    "\n",
    "tar czvf output.tgz sourceFiles\n",
    "\n",
    "example:\n",
    "tar czvf Denver_zipcodes.tgz Denver_zipcodes/\n",
    "\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "**SUBMIT:**\n",
    "- Your jupyter-notebook (1 file)\n",
    "- Your Data file on a zip called _data.zip) (1 file)\n",
    "- Your images (png files)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
