{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style='text-aling:center;color:Navy'>  Big Data Systems - Fall 2021  </h1>\n",
    "<h1 style='text-aling:center;color:Navy'>  Assignment 3  </h1>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This assignment is focused on Data Analysis and Visualization, as well as utilizing some Query language.\n",
    "\n",
    "To complete the assignment, you should complete this notebook by filling in the cells provided."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Submission Deadline: This assignment is due Friday, Mar 17 at 8:59 P.M.</b>\n",
    "\n",
    "A few notes before you start:\n",
    "- Directly sharing answers is not okay, but discussing problems with other students is encouraged.\n",
    "- You should start early so that you have time to get help if you're stuck.\n",
    "\n",
    "- Before continuing the assignment, select \"Save and Checkpoint\" in the File menu and then execute the submit cell below. The result will contain a link that you can use to check that your assignment has been submitted successfully. If you submit more than once before the deadline, we will only grade your final submission. If you mistakenly submit the wrong one, you can head to okpy.org and flag the correct version. There will be another submit cell at the end of the assignment when you finish!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-top: 5px solid orange; margin-top: 1px; margin-bottom: 1px\"></hr>\n",
    "<br>\n",
    "Before you begin completing the assignment, execute the following cell to load the provided tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't change this cell; just run it. \n",
    "# When you log-in please hit return (not shift + return) after typing in your email\n",
    "from client.api.notebook import Notebook\n",
    "ok = Notebook('Assignment3.ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = ok.submit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-top: 5px solid orange; margin-top: 1px; margin-bottom: 1px\"></hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-top: 5px solid purple; margin-top: 1px; margin-bottom: 1px\"></hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"font-size:35px;color:#3665af\">Section 1: Data Analysis </span>\n",
    "\n",
    "This lab will explore the use of Pandas for performing data analysis and MatplotLib for visualizing the results. We will be exploring these tools using a publicly available genome annotation file often used in DNA analysis pipelines. Don't worry if you aren't familiar with genetics, the techniques for managing the data will be the same as any other data set the only difference will be in interpreting the results which is beyond the scope of this assignment.\n",
    "\n",
    "### Template Data Analysis Pipeline\n",
    "These are the steps we will be exploring in this lab in relation to a larger data analysis pipeline:\n",
    "#### 1. Load Data\n",
    "In this section, we will explore both loading a small file into Pandas directly. In the other section of this assignment we  explore loading data from a remote database using Google BigQuery.\n",
    "\n",
    "#### 2. Explore the Data\n",
    "It is very helpful to understand what the data looks like, the types of attributes, number of rows, distribution of values for attributes, etc. Pandas provides functions like ```.head()```, ```.tail()``` and ```.describe()``` to explore the data more analytically. Matplotlib can be used to visualize the data and is very useful for spotting distributions or relations between values. This information can be used to validate our experiment, and inform our predictive model (again, beyond the scope of this assignment).\n",
    "\n",
    "#### 3. Clean the Data\n",
    "Data is never perfect, we'll have missing values, extreme outliers, or values that just make no sense. Luckily, Pandas provides functions like ```.isna()``` to identify missing values. Sometimes cleaning the data can be very involved, as in the case of DNA analysis, but this lab focuses on cleaning by removing extraneous data.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the packages you'll need\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size:30px;color:#3665af;background-color:#E9E9F5;padding:10px;\">1. Loading Data </div>\n",
    "\n",
    "### Gene Annotation\n",
    "This section of the assignment will begin by loading a tabular file into a Pandas dataframe, exploring that data, then cleaning it and visualizing the results. This file contains gene annotations, which are regions of DNA that are 'read' in a cell and contain all the data that makes up an organism, like a human. \n",
    "\n",
    "The first line of code retrieves the data file from an online repository, which is similar in format to a csv file. It can be read using the `read_csv()` method provided by Pandas with tweeked parameters for the specifics of this file type. \n",
    "\n",
    "Since this file is not _exactly_ in a supported file format, the process for loading it has been done for you. But some things to note:\n",
    "1. Pandas has its own command for reading files by type, which loads directly into a dataframe\n",
    "2. We can define our own column names that will appear as the header of the dataframe when Pandas loads the file \n",
    "3. We can specify how Pandas should read the file i.e separator, comment tokens, in chucks, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab the file from the internet \n",
    "!wget ftp://ftp.ensembl.org/pub/release-85/gff3/homo_sapiens/Homo_sapiens.GRCh38.85.gff3.gz\n",
    "    \n",
    "# define the column names, which are not provided in the file\n",
    "col_names = ['seqid', 'source', 'type', 'start', 'end', 'score', 'strand', 'phase', 'attributes']\n",
    "\n",
    "# load the file into a Pandas dataframe\n",
    "# compression = file is compressed using gzip, specify this to read compressed file directly\n",
    "# sep = separator, how each separate data value is separated\n",
    "# comment = lines beginning with this symbol are ignored\n",
    "# low_memory = process whole file at once rather than chunks, prevents mixed types\n",
    "# header = file has no header, tell method not to look for one\n",
    "# names = specify custom column names from list above\n",
    "annotations = pd.read_csv('Homo_sapiens.GRCh38.85.gff3.gz', compression='gzip',\n",
    "                         sep='\\t', comment='#', low_memory=False,\n",
    "                         header=None, names=col_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size:30px;color:#3665af;background-color:#E9E9F5;padding:10px;\">2. Exploring the Data </div>\n",
    "\n",
    "Start by simply printing out the first 10 rows of the annotations to get a sense for the data and its schema. Pandas has a single method for doing this, which can be found in the [documentation for Pandas Dataframes](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html). \n",
    "\n",
    "### Question 1\n",
    "Print out the _first 10_ rows of the annotations dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSERT CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size:20px;color:#F1F8FC;background-color:#0095EA;padding:10px;\">2.1. Closer Look </div>\n",
    "\n",
    "There are 25 chromosomes in this human genome (22 numbered + X + Y + MT [MT = mitochondrial, if you're wondering]).\n",
    "chromosomes are physical divisions of the sequence that can be analysed independently in most cases, making analysis easier by focusing on a smaller portion of the whole sequence. The boundaries of each chromosome in the whole sequence are specified in the annotation file, but first we need to check out how the chromosomes are defined in the annotation file. The chromosome is indicated in the column `seqid`\n",
    "\n",
    "### Question 2\n",
    "Print out the _unique_ `seqid` values of the annotations dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSERT CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "Summarize the annotations dataset. Provide the count, mean, std, min, 25%, 50%, 75%, max values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSERT CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size:30px;color:#3665af;background-color:#E9E9F5;padding:10px;\">3. Cleaning the Data </div>\n",
    "\n",
    "\n",
    "You'll notice there are a lot more than 25 values. The extra values come from regions that are annotated but not included in the main genome because it is not clear where they belong. We will ignore these by filtering them out.\n",
    "\n",
    "We can do this by creating a list of value we want to keep (or reject, but that list would be longer), then query the dataframe for rows with values _isin_ (hint) the list.\n",
    "\n",
    "### Question 4\n",
    "Filter and print the number of unique `seqid's`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list containing seqid values to keep \n",
    "chrs = [str(i) for i in range(1,23)] + ['X', 'Y', 'MT']\n",
    "\n",
    "# query annotations with relevant seqid labels\n",
    "chrs_only = annotations[ __code_here__ ]\n",
    "\n",
    "# print the number of unique seqid's to make sure you filtered correctly\n",
    "len(chrs_only.__code_here__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size:20px;color:#F1F8FC;background-color:#0095EA;padding:10px;\">3.1. Verifying </div>\n",
    "\n",
    "Now that we have the completed portions (the 25 chromosomes) of the genome separated, lets see how much (percent) of the total genome is unassembled. This will help verify how much of the data we will be missing out on if we only base our analysis on the annotated chromosomes compared to using all annotated data. Luckily, there are rows that sumamrize each region (chromosome and unassembled) and contain information about their entire length.\n",
    "\n",
    "First, extract only the rows that summarize each `seqid` region (indicated by a `source` equal to GRCh38). Then, find only unassembled regions and create a new Series containing the length of each region. Finally, sum up the lengths of each chromosome we found in the last cell.\n",
    "\n",
    "### Question 5\n",
    "Find the length of incomplete regions, find the length of genome sequence, and find the percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A source of GRCh38 is used for rows that provide a summary of each seqid value\n",
    "GRCh38_only = annotations[annotations.source == 'GRCh38']\n",
    "\n",
    "# find the length of the incomplete regions\n",
    "# (length = end - start)\n",
    "incomplete_regions = GRCh38_only[GRCh38_only.type == 'supercontig']\n",
    "incomplete_lens = incomplete_regions.__code_here__\n",
    "\n",
    "# then find the total length of the genome sequence (hint: each chromosome's length is given in the end column)\n",
    "total_len = chrs_only[chrs_only.source == 'GRCh38'].__code_here__\n",
    "\n",
    "# find the percentage\n",
    "incomplete_ratio = incomplete_lens.sum() / total_len\n",
    "'{0:.2f}%'.format(incomplete_ratio * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size:20px;color:#F1F8FC;background-color:#0095EA;padding:10px;\">3.2. Plotting </div>\n",
    "\n",
    "\n",
    "Now that we have the chromosomes we want to focus on, we can explore the genes within them. Genes can be any length, but it will be helpful to know the range of length values for choosing an appropriate model in the downstream analysis (beyond the scope of this assignment, but think machine learning or statistical model).\n",
    "\n",
    "The most helpful plot in this situation will likely be a histogram, which will capture the number of genes in a set range of lengths. Which means first, we will find the length of each gene in the annotation file and store as a new column in a dataframe. Then, use Matplotlib to generate a histogram plot with 50 bins for the length and a log-scale y-axis, use the [Matplotlib `hist` documentation](https://matplotlib.org/api/_as_gen/matplotlib.pyplot.hist.html) to find the parameters needed.\n",
    "\n",
    "### Question 6\n",
    "Get the correct genes, compute and store the length of each gene, and create a plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, get only genes from annotated regions (type == gene)\n",
    "genes = chrs_only[ __code_here__ ]\n",
    "\n",
    "# then complute the length of each gene and store as a new column\n",
    "# notice the syntax for adding a new column is fairly simple\n",
    "genes['length'] = __code_here__\n",
    "\n",
    "# setup the matplotlib hist plot with 50 bins and logarithmic scale on the y-axis\n",
    "plt.hist(__code_here__)\n",
    "plt.ylabel('Count')\n",
    "plt.xlabel('Gene Length (bp)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size:20px;color:#F1F8FC;background-color:#0095EA;padding:10px;\">3.3. More Complex Plot </div>\n",
    "\n",
    "Now we're going to make a slightly more complex plot to display 3 variables together in a single 2D plot. Specifically we will plot gene count by chromosome and relate it to chromosome length in a scatter plot. \n",
    "\n",
    "To do this we will need the lengths of each chromosome, and the number of genes in each chromosome. Finding the lengths will be similar to part 3.1, **but** make sure to keep the `seqid` column to set as the new index to join the two dataframes later.\n",
    "\n",
    "The genes per chromosome will also require the `seqid` column for joining, and you will need to use the `reset_index()` function before setting `seqid` as the new index.\n",
    "\n",
    "### Question 7\n",
    "Get chromosome length, count the genes for each chromosome, join the dataframes, and then plot the count against chromosome length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, get the chromosome lengths (only need entries with type==chromosome)\n",
    "chr_lens = __code_here__\n",
    "\n",
    "# next, count genes for each chromosome\n",
    "genes_per_chr = __code_here__\n",
    "\n",
    "# join the dataframes on seqid\n",
    "plot_frame = __code_here__\n",
    "\n",
    "# then plot the count against the chromosome length\n",
    "plt.scatter(plot_frame['end'], plot_frame['source'])\n",
    "plt.ylabel('Gene Length (bp)')\n",
    "plt.xlabel('Chromosome Length (bp)')\n",
    "# labels for each point\n",
    "for idx, p in plot_frame.iterrows():\n",
    "    plt.annotate(idx, xy=(p[1], p[0]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size:30px;color:#3665af;background-color:#E9E9F5;padding:10px;\">4. Concluding Remarks </div>\n",
    "\n",
    "\n",
    "In this part we introduced loading, exploring, and cleaning a small dataset using the Pandas and Matplotlib libraries for Python. This data could be used in later analysis for analyzing genes at the chromosome-level, a process known as Variant Calling in a standard genome analysis pipeline. This data could also be used in a machine learning, statistical, or other predictive model to make data-driven decisions.\n",
    "\n",
    "Both Pandas and Matplotlib have much more depth than what was presented here, but you can leverage a similar analysis pattern to other datasets using the specific tools to transform and visualize as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size:30px;color:#3665af;background-color:#e1dfb1;padding:10px;\">5. Exercise </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This exercise will have you load, explore, and clean a dataset. The dataset is called train.csv and can be found in Jupyterhub.\n",
    "\n",
    "- Load and display the first 10 rows\n",
    "- Summarize the dataset\n",
    "- Remove columns with any missing values\n",
    "- Create a 2D scatter plot with the following 3 variables: LotArea, YearBuilt, and SalePrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and display the first 10 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove columns with any missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 2D scatter plot with the following 3 variables: LotArea, YearBuilt, and SalePrice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-top: 5px solid purple; margin-top: 1px; margin-bottom: 1px\"></hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"font-size:35px;color:#3665af\">Section 2: Query Language </span>\n",
    "\n",
    "\n",
    "In this section of the assignment, we will be using Google BigQuery to query data from the \"1000 Genomes Project\", a publicly available database that contains information regarding known variants, genetic aberrations that can be the underlying cause of a disease. We will query this information and calculate a single analytical metric, which could normally be used to help verify the results of a DNA analysis pipeline, but in this case the data has been verified already so it can be used to verify your query instead.\n",
    "\n",
    "Information about the datasets can be found [here](http://googlegenomics.readthedocs.io/en/latest/use_cases/discover_public_data/1000_genomes.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import a library for connecting Pandas to BigQuery\n",
    "import pandas as pd\n",
    "import pandas_gbq as pdgbq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size:30px;color:#3665af;background-color:#E9E9F5;padding:10px;\">1. Setup Connection </div>\n",
    "\n",
    "Connect to BigQuery and run a test query, this will require a project with credits, enabling BigQuery API for your project, and authorization for this notebook to use BigQuery.\n",
    "\n",
    "To enable the BigQuery API for your project go [here](https://console.cloud.google.com/flows/enableapi?apiid=bigquery).\n",
    "\n",
    "Running the sample query below will provide a prompt to allow access for this notebook.\n",
    "\n",
    "The pandas BigQuery extension will return the results of each query into a Pandas Dataframe for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is a template query you can use to test your connection: \n",
    "query = 'SELECT * '\n",
    "query += 'FROM `genomics-public-data.1000_genomes.sample_info` '\n",
    "query += 'LIMIT 25'\n",
    "\n",
    "# Insert your BigQuery Project ID Here\n",
    "# Can be found in the Google web console https://console.cloud.google.com\n",
    "projectid = \"__project_id_here__\"\n",
    "\n",
    "# run a simple query, here we print the results without storing them so you can see it is a dataframe\n",
    "# NOTE!! Google will ask you to authorize pandas when running for the first time!\n",
    "pdgbq.read_gbq(query, projectid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size:30px;color:#3665af;background-color:#E9E9F5;padding:10px;\">2. Writing a Query </div>\n",
    "\n",
    "\n",
    "Now we can try a slightly larger query. The 1000 Genomes variant dataset contains over 3TB of genetic variants, which we can run analytical queries on in seconds using BigQuery.\n",
    "\n",
    "We will begin by querying the dataset to get the reference_name, reference_bases, and alternate_bases that contain only one reference_base *and* one alternate_base. We will test these in the next step.\n",
    "\n",
    "Query the [genomics-public-data:1000_genomes.variants] table. The results are >40M rows, so you can limit to ~50,000 rows to make the query run in a reasonable amount of time.\n",
    "\n",
    "BigQuery SQL documentation can be found [here](https://cloud.google.com/bigquery/docs/reference/standard-sql/functions-and-operators)\n",
    "\n",
    "### Question 1\n",
    "Write a query to get the reference_name, reference_bases, and alternate_bases that contains only <b>one</b> reference_base *and* <b>one</b> alternate_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '__code_here__ '\n",
    "\n",
    "# this query will take some time depending on how many rows you want\n",
    "data = pdgbq.read_gbq(query, projectid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size:30px;color:#3665af;background-color:#E9E9F5;padding:10px;\">3. Interpreting the Results </div>\n",
    "\n",
    "\n",
    "We have provided two functions that can be applied to the results of the above query. The functions calculate whether a variant was a transition or a transversion. We can compute these, then take the ratio of the sum of each as a metric for verifying our dataset (in this case verifying the query).\n",
    "\n",
    "Remeber that the query returns a dataframe, so you can use any function from the Pandas library that applies to a dataframe. \n",
    "\n",
    "#### Below is an explanation of where this metric comes from for those interested, but reading the below paragraph is not required for this assignment!\n",
    "Transitions/Transversions are terminology for an interesting effect of the chemistry of DNA, which is made of 4 molecules divided into 2 shapes (pyrimidines and purines). A molecule of one shape is more likely to change to the other of the same shape than it is to one of the opposite shape. We can look at the ratio of these transitions to transversions over our entire dataset or a sampling of it as one of a few metrics to verify if the variants we found are correct. Genomes will have a set range of valid Ti/Tv ratios depending on the organism (humans are ~2.1-2.8). [For more about the molecules and their shapes](https://en.wikipedia.org/wiki/Nucleobase).\n",
    "\n",
    "### Question 2\n",
    "Apply the transitions and transversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyrimidines = ['A', 'G']\n",
    "purines = ['T', 'C']\n",
    "\n",
    "# transitions are a mutation to a base with a similar shape (e.g pyrimidine -> pyrimidine)\n",
    "def transitions(row):\n",
    "    if row['reference_bases'] in pyrimidines and row['alternate_bases'] in pyrimidines:\n",
    "        return 1\n",
    "    elif row['reference_bases'] in purines and row['alternate_bases'] in purines:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "# transversions are a mutation to a base with a different shape (e.g pyrimidine -> purine)\n",
    "def transversions(row):\n",
    "    if row['reference_bases'] in pyrimidines and row['alternate_bases'] in purines:\n",
    "        return 1\n",
    "    elif row['reference_bases'] in purines and row['alternate_bases'] in pyrimidines:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "# apply the functions above to the data set \n",
    "# queried from the 1000 Genomes database\n",
    "\n",
    "# ti = apply transitions\n",
    "data_ti = data.__code_here__\n",
    "# tv = apply transversions\n",
    "data_tv = data.__code_here__\n",
    "\n",
    "# the final output should be between 2.1-2.8, which is normal for humans\n",
    "print(data_ti.sum() / data_tv.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size:30px;color:#3665af;background-color:#E9E9F5;padding:10px;\">4. More Advanced Query </div>\n",
    "\n",
    "\n",
    "Now we will run a query using a user defined function (UDF) which in this case is small enough to include in the query. We have provided the function (written in Javascript) for you to examine the semantics of if you want to try writing your own in the future. \n",
    "\n",
    "This query will require the Google BigQuery client for Python (we are no longer using Pandas) due to the UDF. This will also require a key from your account, instructions for which are provided below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports the Google Cloud client library\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need to add credentials to run BigQuery from this Jupyter notebook\n",
    "go to [this page](https://console.cloud.google.com/apis/credentials/serviceaccountkey), then\n",
    "select this notebook for the account, select JSON and generate the key.\n",
    "the key will download to your device, then either copy it to the directory\n",
    "where this notebook is located and paste the name of the JSON file below,\n",
    "or paste the full path to the JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# link credentials file\n",
    "credentials = service_account.Credentials.from_service_account_file('__JSON_path_here__')\n",
    "\n",
    "# Instantiates a client\n",
    "bigquery_client = bigquery.Client(project=projectid, credentials=credentials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "Count the number of transversions that occur in each chromosome using the UDF.\n",
    "\n",
    "Hint: \n",
    "This query will again select the reference_name, and reference_bases and alternate_bases of length one. This time though, we will be counting per reference_name using the UDF provided. The trick here is that alternate_bases are an array of strings in this dataset, so you will need to turn that array into a single string somehow before checking its length. The next cell will print out the results of your query and the query will not actually run until the results are printed (lazily evaluated), so if you want to experiment with different queries, you can use the BigQuery interface [here](https://bigquery.cloud.google.com/table/genomics-public-data:1000_genomes.variants)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the number of transversions that occur in each chromosome\n",
    "# (The  UDF)\n",
    "query = 'CREATE TEMPORARY FUNCTION tv(ref STRING, alt STRING) '\n",
    "query += 'RETURNS INT64 '\n",
    "query += r'''LANGUAGE js AS \"\"\" '''\n",
    "query += 'var pyr = [\"A\", \"G\"]; '\n",
    "query += 'var pur = [\"T\", \"C\"]; '\n",
    "query += 'if ((pyr.includes(ref) && pur.includes(alt)) || (pur.includes(ref) && pyr.includes(alt))) {return 1;} '\n",
    "query += 'else {return 0;}'\n",
    "query += r''' \"\"\"; '''\n",
    "\n",
    "# select the reference_name and the count of tv's using the above function, note function name and parameters above\n",
    "query += 'SELECT __code_here__ '\n",
    "query += 'FROM `genomics-public-data.1000_genomes.variants` '\n",
    "query += '__code_here__'\n",
    "\n",
    "data = bigquery_client.query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this to print the results of your query\n",
    "# notice how this method differs from the Pandas extension that stores the query results in a dataframe\n",
    "print(\"Chromosome, Count\")\n",
    "for row in data:\n",
    "    print(row[0] + ', ' + str(row[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<div style=\"font-size:30px;color:#3665af;background-color:#E9E9F5;padding:10px;\">5. Concluding Remarks </div>\n",
    "\n",
    "\n",
    "This was a quick look at BigQuery for running analytical queries on a publically available genomics dataset to explore the Ti/Tv ratio. This technique can be applied to DNA sequencing experiments to verify the results of the data cleaning and analysis. If you are interested in the DNA analysis pipeline and BigQuery, an even more advanced version of this query with UDF's can be found [here](https://cloud.google.com/life-sciences/docs/how-tos/analyze-variants).\n",
    "\n",
    "BigQuery is similar to other big data query languages such as Apache Hive or Impala, so you can apply the information here to the other languages. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-top: 5px solid purple; margin-top: 1px; margin-bottom: 1px\"></hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-top: 5px solid orange; margin-top: 1px; margin-bottom: 1px\"></hr>\n",
    "\n",
    "Submission: Once you're finished, select \"Save and Checkpoint\" in the File menu and then execute the submit cell below. The result will contain a link that you can use to check that your assignment has been submitted successfully. If you submit more than once before the deadline, we will only grade your final submission. If you mistakenly submit the wrong one, you can go to the URL that you got at the very beginning of this homework and flag the correct version. To do so, go to the website, click on this assignment, and find the version you would like to have graded. There should be an option to flag that submission for grading. Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = ok.submit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-top: 5px solid orange; margin-top: 1px; margin-bottom: 1px\"></hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
